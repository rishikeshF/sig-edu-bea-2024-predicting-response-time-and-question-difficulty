{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a0dbd61-b7b0-4965-aa54-f5e988b80a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries/frameworks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "354e4cfd-e04b-44d4-b547-1712c39a6029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>ItemStem_Text</th>\n",
       "      <th>Answer__A</th>\n",
       "      <th>Answer__B</th>\n",
       "      <th>Answer__C</th>\n",
       "      <th>Answer__D</th>\n",
       "      <th>Answer__E</th>\n",
       "      <th>Answer__F</th>\n",
       "      <th>Answer__G</th>\n",
       "      <th>Answer__H</th>\n",
       "      <th>Answer__I</th>\n",
       "      <th>Answer__J</th>\n",
       "      <th>Answer_Key</th>\n",
       "      <th>Answer_Text</th>\n",
       "      <th>ItemType</th>\n",
       "      <th>EXAM</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Response_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>Over 1 year, a study is conducted to assess th...</td>\n",
       "      <td>Case-control study</td>\n",
       "      <td>Crossover study</td>\n",
       "      <td>Open-labeled clinical trial</td>\n",
       "      <td>Randomized clinical trial</td>\n",
       "      <td>Single-blind, randomized, controlled trial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>Open-labeled clinical trial</td>\n",
       "      <td>Text</td>\n",
       "      <td>STEP 1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>111.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>288</td>\n",
       "      <td>A previously healthy 52-year-old woman comes t...</td>\n",
       "      <td>Calcitriol production by activated macrophages</td>\n",
       "      <td>Local resorption of bone by metastases</td>\n",
       "      <td>Parathyroid hormone-related peptide secretion</td>\n",
       "      <td>Secretion of parathyroid hormone</td>\n",
       "      <td>Secretion of thyroid-stimulating hormone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Calcitriol production by activated macrophages</td>\n",
       "      <td>Text</td>\n",
       "      <td>STEP 1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>83.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemNum                                      ItemStem_Text  \\\n",
       "0       91  Over 1 year, a study is conducted to assess th...   \n",
       "1      288  A previously healthy 52-year-old woman comes t...   \n",
       "\n",
       "                                        Answer__A  \\\n",
       "0                              Case-control study   \n",
       "1  Calcitriol production by activated macrophages   \n",
       "\n",
       "                                Answer__B  \\\n",
       "0                         Crossover study   \n",
       "1  Local resorption of bone by metastases   \n",
       "\n",
       "                                       Answer__C  \\\n",
       "0                    Open-labeled clinical trial   \n",
       "1  Parathyroid hormone-related peptide secretion   \n",
       "\n",
       "                          Answer__D  \\\n",
       "0         Randomized clinical trial   \n",
       "1  Secretion of parathyroid hormone   \n",
       "\n",
       "                                    Answer__E Answer__F Answer__G Answer__H  \\\n",
       "0  Single-blind, randomized, controlled trial         0         0         0   \n",
       "1    Secretion of thyroid-stimulating hormone         0         0         0   \n",
       "\n",
       "  Answer__I Answer__J Answer_Key  \\\n",
       "0         0         0          C   \n",
       "1         0         0          A   \n",
       "\n",
       "                                      Answer_Text ItemType    EXAM  \\\n",
       "0                     Open-labeled clinical trial     Text  STEP 1   \n",
       "1  Calcitriol production by activated macrophages     Text  STEP 1   \n",
       "\n",
       "   Difficulty  Response_Time  \n",
       "0        0.86         111.21  \n",
       "1        0.44          83.94  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel( 'train_final.xlsx' )\n",
    "test_data = pd.read_excel( 'test_final.xlsx' )\n",
    "test_target = pd.read_excel( 'gold_final.xlsx' )\n",
    "test_data = pd.merge( test_data, test_target, on = 'ItemNum' ) \n",
    "test_data.fillna( 0, inplace=True) \n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f488946-95cc-4243-ab62-37c842515232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bergen.edu/ELRC/connectingwords.html#:~:text=ADDITION%3A%20also%2C%20besides%2C%20equally,%2C%20moreover%2C%20next%2C%20too.\n",
    "\n",
    "connectives = [ 'also', 'besides', 'equally', 'further', 'furthermore', 'in addition', 'moreover', 'next', 'too', 'also', 'likewise', 'moreover', \\\n",
    "'however', 'on the contrary', 'on the other hand', 'in contrast', 'nevertheless', 'for example', 'for instance', 'in fact', \\\n",
    "'finally', 'in brief', 'in conclusion', 'in other words', 'in short', 'in summary', 'therefore', 'accordingly', 'as a result', \\\n",
    "'consequently', 'for this reason', 'therefore', 'afterward', 'in the meantime', 'later', 'meanwhile', 'next', 'second', 'earlier', \\\n",
    "'finally', 'first', 'soon', 'still', 'then', 'third' ]\n",
    "\n",
    "def vectorizeEXAM(x):\n",
    "    if x == 'STEP 1' : \n",
    "        return .33\n",
    "    elif x == 'STEP 2' : \n",
    "        return .66\n",
    "    else: \n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed86d826-6d7f-48dd-86ae-fc5860252357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "466it [00:00, 2073.08it/s]\n",
      "201it [00:00, 2262.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def text_feature( data ):\n",
    "    data = data.astype('str')\n",
    "    num_of_words = []\n",
    "    num_of_uniq_words = []\n",
    "    num_of_additives = []\n",
    "    num_of_uniq_additives = []\n",
    "    num_of_normalized_additives = []\n",
    "    num_of_numbers = []\n",
    "    num_of_letters = []\n",
    "    \n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        text = row['ItemStem_Text']\n",
    "        for option in [ 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J' ] : \n",
    "            if row[ 'Answer__' + option ] != 0 : \n",
    "                text += ' ' + row[ 'Answer__' + option ]\n",
    "                \n",
    "        text = text.lower()\n",
    "\n",
    "        num_of_words.append(len(text.split()))\n",
    "        num_of_uniq_words.append(len(set(text.split()))) \n",
    "        num_of_additives.append(sum([ text.count(i) for i in connectives ]))\n",
    "        num_of_uniq_additives.append(sum([ 1 if text.count(i) > 0 else 0 for i in connectives ]))\n",
    "        num_of_normalized_additives.append(sum([ text.count(i) for i in connectives ])/num_of_words[-1])\n",
    "        num_of_numbers.append(sum(c.isdigit() for c in text))\n",
    "        num_of_letters.append(sum(c.isalpha() for c in text))\n",
    "\n",
    "    df['ItemType_num'] = df.ItemType.apply(lambda x: 0 if x == 'PIX' else 1 ) \n",
    "    df['EXAM_num'] = df.EXAM.apply( vectorizeEXAM )\n",
    "    \n",
    "    featurized = pd.DataFrame( {\n",
    "                  'num_of_words' : num_of_words,\n",
    "                  'num_of_uniq_words' : num_of_uniq_words,\n",
    "                  'num_of_additives' : num_of_additives,\n",
    "                  'num_of_uniq_additives' : num_of_uniq_additives,\n",
    "                  'num_of_normalized_additives' : num_of_normalized_additives, \n",
    "                  'num_of_numbers' : num_of_numbers,\n",
    "                  'num_of_letters' : num_of_letters}\n",
    "                             )\n",
    "    \n",
    "    featurized['ItemType_num'] = data.ItemType.apply(lambda x: 0 if x == 'PIX' else 1 ) \n",
    "    featurized['EXAM_num'] = data.EXAM.apply( vectorizeEXAM )\n",
    "    \n",
    "    return featurized\n",
    "\n",
    "featurized_data = text_feature( df )\n",
    "featurized_test_data = text_feature( test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ccbce8a-c437-449c-9878-0a5b4d40243e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_words</th>\n",
       "      <th>num_of_uniq_words</th>\n",
       "      <th>num_of_additives</th>\n",
       "      <th>num_of_uniq_additives</th>\n",
       "      <th>num_of_normalized_additives</th>\n",
       "      <th>num_of_numbers</th>\n",
       "      <th>num_of_letters</th>\n",
       "      <th>ItemType_num</th>\n",
       "      <th>EXAM_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>26</td>\n",
       "      <td>617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>18</td>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_of_words  num_of_uniq_words  num_of_additives  num_of_uniq_additives  \\\n",
       "0           119                 79                 0                      0   \n",
       "1           108                 75                 2                      1   \n",
       "2           124                 84                 2                      2   \n",
       "\n",
       "   num_of_normalized_additives  num_of_numbers  num_of_letters  ItemType_num  \\\n",
       "0                     0.000000              13             606             1   \n",
       "1                     0.018519              26             617             1   \n",
       "2                     0.016129              18             561             1   \n",
       "\n",
       "   EXAM_num  \n",
       "0      0.33  \n",
       "1      0.33  \n",
       "2      0.66  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurized_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3ec04e1-dce9-4ad1-ae10-ebecf79a8946",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = featurized_data.columns.values\n",
    "y_1 = df['Difficulty']  \n",
    "y_2 = df['Response_Time'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e59c0be0-71a2-4f3b-b979-93279465a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train1, X_test1, y_train1, y_test1 = train_test_split( featurized_data[X_cols ], y_1, test_size=0.1, random_state=1 )\n",
    "#X_train2, X_test2, y_train2, y_test2 = train_test_split( featurized_data[X_cols ], y_2, test_size=0.1, random_state=1 )\n",
    "\n",
    "#X_train1, X_val1, y_train1, y_val1 = train_test_split( df[X_cols], y_1, test_size=0.1, random_state=1 )\n",
    "#X_train2, X_val2, y_train2, y_val2 = train_test_split( df[X_cols], y_2, test_size=0.1, random_state=1 )\n",
    "\n",
    "X_train, X_test = featurized_data[X_cols ], featurized_test_data[X_cols ]\n",
    "y_train1, y_train2, y_test1, y_test2 = y_1, y_2, test_data['Difficulty'], test_data['Response_Time']\n",
    "#X_test1 = test_data[X_cols]\n",
    "#X_test2 = test_data[X_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f765cf0-19e4-4fa0-be88-f7f2b59f5d2c",
   "metadata": {},
   "source": [
    "### Task 1: Predicting Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31e0bdd-933b-4f76-a5db-aed1d8bc7d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'n_estimators': 700}\n",
      "0.30395751597905185\n",
      "CPU times: total: 1min 30s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=0)\n",
    "param_dict = { 'n_estimators': [ 700, 900], \"max_depth\": [3,5] }\n",
    "model_rfr = GridSearchCV( rfr ,param_grid=param_dict, cv=5, refit = True)\n",
    "model_rfr.fit(X_train,y_train1)\n",
    "print(model_rfr.best_params_)\n",
    "\n",
    "y_predicted = model_rfr.predict(X_test)\n",
    "rfr_rmse = mean_squared_error( y_test1, y_predicted, squared=False ) \n",
    "print(rfr_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264efdf4-3c97-4906-80e2-cea2dfc41a28",
   "metadata": {},
   "source": [
    "### Task 2: Predicting Response Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11689b50-0aed-4351-9577-d83ff07f5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'n_estimators': 800}\n",
      "26.234097362989363\n",
      "CPU times: total: 1min 26s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=0)\n",
    "param_dict = { 'n_estimators': [800, 900], \"max_depth\": [3,5,6] }\n",
    "model_rfr = GridSearchCV( rfr ,param_grid=param_dict, cv=5, refit = True)\n",
    "model_rfr.fit(X_train,y_train2)\n",
    "print(model_rfr.best_params_)\n",
    "\n",
    "y_predicted = model_rfr.predict(X_test)\n",
    "rfr_rmse = mean_squared_error( y_test2, y_predicted, squared=False ) \n",
    "print(rfr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75357b7-db3a-4706-856e-aa93403ae7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e645e17c-92c2-4909-910b-0de2ddce3c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ItemNum', 'ItemStem_Text', 'Answer__A', 'Answer__B', 'Answer__C',\n",
       "       'Answer__D', 'Answer__E', 'Answer__F', 'Answer__G', 'Answer__H',\n",
       "       'Answer__I', 'Answer__J', 'Answer_Key', 'Answer_Text', 'ItemType',\n",
       "       'EXAM', 'Difficulty', 'Response_Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fb804d-f858-49ec-ad48-d3e72bcd6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = df.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad4eae8f-cec7-4008-82bf-8dfe5d4d2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = df[ ~df['ItemNum'].isin(sample_test['ItemNum'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd72f7a7-e27b-49cd-989e-cb86fc3af1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 18)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca2ff18-1a26-426b-9c26-5a8a02aca661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train.to_csv('sample_train.csv', index=None)\n",
    "sample_test.to_csv('sample_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7be865ee-8de5-4e2f-8e4d-9505eed5c254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7575803-49e5-4b1e-a604-7fdcab3c16fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cd67a33-d1b7-439a-bc84-ad2b8e610747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "466it [00:00, 1978.45it/s]\n",
      "201it [00:00, 2252.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel( 'train_final.xlsx' )\n",
    "test = pd.read_excel( 'test_final.xlsx')\n",
    "featurized_data = text_feature( df )\n",
    "test_data = text_feature( test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd72bd82-e952-4302-995b-9a1b07249985",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = featurized_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45c97caa-7888-42e3-b2bf-93fdbb5b7ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['num_of_words', 'num_of_uniq_words', 'num_of_additives',\n",
       "       'num_of_uniq_additives', 'num_of_normalized_additives',\n",
       "       'num_of_numbers', 'num_of_letters', 'ItemType_num', 'EXAM_num'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8499d834-71c3-4dc8-b811-efb39278e6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ItemNum', 'ItemStem_Text', 'Answer__A', 'Answer__B', 'Answer__C',\n",
       "       'Answer__D', 'Answer__E', 'Answer__F', 'Answer__G', 'Answer__H',\n",
       "       'Answer__I', 'Answer__J', 'Answer_Key', 'Answer_Text', 'ItemType',\n",
       "       'EXAM', 'Difficulty', 'Response_Time', 'ItemType_num', 'EXAM_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5f3b6e1-1023-40a3-be2a-87fe62d2ff8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      111.21\n",
       "1       83.94\n",
       "2       87.82\n",
       "3       54.87\n",
       "4       69.11\n",
       "        ...  \n",
       "461     77.18\n",
       "462    129.56\n",
       "463     78.03\n",
       "464     79.69\n",
       "465     96.63\n",
       "Name: Response_Time, Length: 466, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Response_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65acb697-ebf8-4afa-b1a3-7e5ee6a4e545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=5, n_estimators=900, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=5, n_estimators=900, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=5, n_estimators=900, random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurized_data\n",
    "rfr = RandomForestRegressor(random_state=0, max_depth= 5, n_estimators= 900)\n",
    "rfr.fit( featurized_data,  df['Response_Time'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8764719-9cca-4c33-a306-ec7953ec6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_time = rfr.predict( test_data ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6ccfe87-4397-42c0-bac2-000e83312f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      552\n",
       "1       16\n",
       "2      441\n",
       "3      219\n",
       "4      600\n",
       "      ... \n",
       "196    612\n",
       "197    315\n",
       "198    509\n",
       "199    550\n",
       "200    290\n",
       "Name: ItemNum, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ItemNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4610433f-0d82-4ef5-87f2-26a876893dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df = pd.DataFrame( { 'ItemNum' : test['ItemNum'], 'Prediction' : predicted_time } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1683856c-ff1d-4ca1-9dc3-3dc755110071",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df.to_csv( 'Rishikesh_Fulari_Response_Time_Predictions_run_1.csv', index=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3de00b91-7d3f-4436-a001-77e17712414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "def find_best_classical_model(X_train,X_test, y_train, y_test):\n",
    "    \n",
    "    # Model 1 : Linear Regression \n",
    "    model_1_lr = LinearRegression()\n",
    "    model_1_lr.fit(X_train, y_train)\n",
    "    #y_predicted_1 = model_1_lr.predict(X_valid)\n",
    "    #model_1_rmse = mean_squared_error( y_valid, y_predicted_1, squared=False ) \n",
    "    predicted_lr = model_1_lr.predict(X_test)\n",
    "    test_rmse_lr = mean_squared_error( y_test, predicted_lr, squared=False )\n",
    "    \n",
    "    # Model 2 : Decision Tree classifier\n",
    "    dtr = DecisionTreeRegressor(random_state=0)\n",
    "    param_dict_2 = { \"max_depth\": [3,5] }\n",
    "    model_2_dtr = GridSearchCV( dtr ,param_grid=param_dict_2, cv=3, refit = True)\n",
    "    model_2_dtr.fit(X_train,y_train)\n",
    "    #y_predicted_2 = model_2_dtr.predict(X_valid)\n",
    "    #model_2_rmse = mean_squared_error( y_valid, y_predicted_2, squared=False ) \n",
    "    predicted_dt = model_2_dtr.predict(X_test)\n",
    "    test_rmse_dt = mean_squared_error( y_test, predicted_dt, squared=False )\n",
    "\n",
    "    # Model 3 : KNN\n",
    "    knn = KNeighborsRegressor(weights=\"distance\", metric= \"minkowski\", p = 2)\n",
    "    param_dict_3 = { 'n_neighbors' : [3,5, 7] }\n",
    "    model_3_knn = GridSearchCV(knn,param_grid=param_dict_3, cv=3 )\n",
    "    model_3_knn.fit(X_train,y_train)\n",
    "    #y_predicted_3 = model_3_knn.predict(X_valid)\n",
    "    #model_3_rmse = mean_squared_error( y_valid, y_predicted_3, squared=False ) \n",
    "    predicted_knn = model_3_knn.predict(X_test)\n",
    "    test_rmse_knn = mean_squared_error( y_test, predicted_knn, squared=False )\n",
    "\n",
    "    # Model 4 : XGBoost\n",
    "    regressor=xgb.XGBRegressor(eval_metric='rmse')\n",
    "    param_dict_4 = {\"max_depth\": [3, 5], \"n_estimators\": [600, 700]}\n",
    "    search = GridSearchCV(regressor, param_dict_4, cv=5).fit(X_train, y_train)\n",
    "    regressor=xgb.XGBRegressor(n_estimators  = search.best_params_[\"n_estimators\"],\n",
    "                               max_depth     = search.best_params_[\"max_depth\"],\n",
    "                               eval_metric='rmse')\n",
    "    regressor.fit(X_train, y_train)\n",
    "    #y_predicted_4 = regressor.predict(X_valid)\n",
    "    #model_4_rmse = mean_squared_error( y_valid, y_predicted_4, squared=False )\n",
    "    predicted_xgb = regressor.predict(X_test)\n",
    "    test_rmse_xgb = mean_squared_error( y_test, predicted_xgb, squared=False )\n",
    "\n",
    "    # Model 5 : GBDT\n",
    "    gbdt_regressor = GradientBoostingRegressor(random_state=0)\n",
    "    param_dict_5 =  {\"max_depth\": [3,5], \"n_estimators\": [600, 700]}\n",
    "    model_5_gbdt = GridSearchCV(gbdt_regressor, param_grid=param_dict_5, cv=3, refit=True )\n",
    "    model_5_gbdt.fit(X_train,y_train)\n",
    "    #y_predicted_5 = model_5_gbdt.predict(X_valid)\n",
    "    #model_5_rmse = mean_squared_error( y_valid, y_predicted_5, squared=False )\n",
    "    predicted_gbdt = model_5_gbdt.predict(X_test)\n",
    "    test_rmse_dt = mean_squared_error( y_test, predicted_gbdt, squared=False )\n",
    "\n",
    "    model_names = [\"Linear Regression\",\"Decision Trees\",\"KNN\",\"XGBoost\",\"GBDT\"]\n",
    "    #rmse_scores = [ model_1_rmse, model_2_rmse, model_3_rmse, model_4_rmse, model_5_rmse ]\n",
    "    test_rmse = [ test_rmse_lr, test_rmse_dt, test_rmse_knn, test_rmse_xgb, test_rmse_dt ]\n",
    "    \n",
    "    return model_names, test_rmse\n",
    "\n",
    "model_names, test_rmse_task1 = find_best_classical_model(X_train, X_test, y_train1, y_test1)   \n",
    "model_names, test_rmse_task2 = find_best_classical_model(X_train, X_test, y_train2, y_test2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c75ccaaf-7e27-412f-98a5-fd0eea9705d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear Regression', 'Decision Trees', 'KNN', 'XGBoost', 'GBDT']\n",
      "[0.3028678584809251, 0.34825993895558943, 0.324088535092072, 0.3536270837096936, 0.34825993895558943]\n",
      "[26.181892002473468, 28.862525636492872, 29.57465522392491, 28.64420986158485, 28.862525636492872]\n"
     ]
    }
   ],
   "source": [
    "print(model_names)\n",
    "print(test_rmse_task1)\n",
    "print(test_rmse_task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc9f773c-19d9-4a88-a439-9cff5cc01877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd13f9-9f02-44ea-9b7e-398fc6bdf934",
   "metadata": {},
   "outputs": [],
   "source": [
    "9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
