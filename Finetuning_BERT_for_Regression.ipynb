{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Z3r4KypMlLBB",
   "metadata": {
    "id": "Z3r4KypMlLBB"
   },
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers\n",
    "# reference: https://medium.com/ilb-labs-publications/fine-tuning-bert-for-a-regression-task-is-a-description-enough-to-predict-a-propertys-list-price-cf97cd7cb98a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d652d5c6-86a4-44af-9dd5-7b0a67be5fb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "d652d5c6-86a4-44af-9dd5-7b0a67be5fb4",
    "outputId": "777c4714-9eb0-40a5-c603-6ae65638b15b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemNum</th>\n",
       "      <th>ItemStem_Text</th>\n",
       "      <th>Answer__A</th>\n",
       "      <th>Answer__B</th>\n",
       "      <th>Answer__C</th>\n",
       "      <th>Answer__D</th>\n",
       "      <th>Answer__E</th>\n",
       "      <th>Answer__F</th>\n",
       "      <th>Answer__G</th>\n",
       "      <th>Answer__H</th>\n",
       "      <th>Answer__I</th>\n",
       "      <th>Answer__J</th>\n",
       "      <th>Answer_Key</th>\n",
       "      <th>Answer_Text</th>\n",
       "      <th>ItemType</th>\n",
       "      <th>EXAM</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Response_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>Over 1 year, a study is conducted to assess th...</td>\n",
       "      <td>Case-control study</td>\n",
       "      <td>Crossover study</td>\n",
       "      <td>Open-labeled clinical trial</td>\n",
       "      <td>Randomized clinical trial</td>\n",
       "      <td>Single-blind, randomized, controlled trial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>Open-labeled clinical trial</td>\n",
       "      <td>Text</td>\n",
       "      <td>STEP 1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>111.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>288</td>\n",
       "      <td>A previously healthy 52-year-old woman comes t...</td>\n",
       "      <td>Calcitriol production by activated macrophages</td>\n",
       "      <td>Local resorption of bone by metastases</td>\n",
       "      <td>Parathyroid hormone-related peptide secretion</td>\n",
       "      <td>Secretion of parathyroid hormone</td>\n",
       "      <td>Secretion of thyroid-stimulating hormone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>Calcitriol production by activated macrophages</td>\n",
       "      <td>Text</td>\n",
       "      <td>STEP 1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>83.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemNum                                      ItemStem_Text  \\\n",
       "0       91  Over 1 year, a study is conducted to assess th...   \n",
       "1      288  A previously healthy 52-year-old woman comes t...   \n",
       "\n",
       "                                        Answer__A  \\\n",
       "0                              Case-control study   \n",
       "1  Calcitriol production by activated macrophages   \n",
       "\n",
       "                                Answer__B  \\\n",
       "0                         Crossover study   \n",
       "1  Local resorption of bone by metastases   \n",
       "\n",
       "                                       Answer__C  \\\n",
       "0                    Open-labeled clinical trial   \n",
       "1  Parathyroid hormone-related peptide secretion   \n",
       "\n",
       "                          Answer__D  \\\n",
       "0         Randomized clinical trial   \n",
       "1  Secretion of parathyroid hormone   \n",
       "\n",
       "                                    Answer__E Answer__F Answer__G Answer__H  \\\n",
       "0  Single-blind, randomized, controlled trial         0         0         0   \n",
       "1    Secretion of thyroid-stimulating hormone         0         0         0   \n",
       "\n",
       "  Answer__I Answer__J Answer_Key  \\\n",
       "0         0         0          C   \n",
       "1         0         0          A   \n",
       "\n",
       "                                      Answer_Text ItemType    EXAM  \\\n",
       "0                     Open-labeled clinical trial     Text  STEP 1   \n",
       "1  Calcitriol production by activated macrophages     Text  STEP 1   \n",
       "\n",
       "   Difficulty  Response_Time  \n",
       "0        0.86         111.21  \n",
       "1        0.44          83.94  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries/frameworks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read data into a pandas dataframe\n",
    "df = pd.read_excel( 'train_final.xlsx' )\n",
    "df.fillna(0, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f50746b-ce29-4095-bfdc-f82eb1f078ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "0f50746b-ce29-4095-bfdc-f82eb1f078ed",
    "outputId": "724d988d-23b1-44b8-f091-1b5d32a3c973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of words')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_cols = ['ItemStem_Text', 'Answer__A', 'Answer__B', 'Answer__C', 'Answer__D', 'Answer__E', 'Answer__F', 'Answer__G', 'Answer__H',\n",
    "              'Answer__I', 'Answer__J', 'Answer_Text' ]\n",
    "df[selected_cols] = df[selected_cols].astype('str')\n",
    "text_input = []\n",
    "text_corpus = []\n",
    "for ind, row in df.iterrows():\n",
    "    text, text_ = [], ''\n",
    "    for col in selected_cols:\n",
    "        if row[col] != 0 :\n",
    "            text += row[col].split()\n",
    "            text_ += ' ' + row[col]\n",
    "    text_input.append( text )\n",
    "    text_corpus.append( text_ )\n",
    "\n",
    "lengths = [ len(text) for text in text_input ]\n",
    "plt.hist(lengths, bins=50, density=True, alpha=0.5, color='skyblue');\n",
    "plt.xlabel('Number of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af30757-7cc1-4728-96dd-5318e38d5c87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8af30757-7cc1-4728-96dd-5318e38d5c87",
    "outputId": "e8c72a3c-78d0-49a4-8180-3ee35eaf819e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 466)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths), len(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d153ca6-2a16-4f4b-b259-0579512428e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d153ca6-2a16-4f4b-b259-0579512428e8",
    "outputId": "f7206f3c-bc18-4627-c5b7-14d99b3f2e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "def create_dataloaders(inputs, masks, labels, batch_size):\n",
    "    input_tensor = torch.tensor(inputs)\n",
    "    mask_tensor = torch.tensor(masks)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    dataset = TensorDataset(input_tensor, mask_tensor, labels_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size,shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "class bertRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, drop_rate=0.2, freeze_bert=False):\n",
    "\n",
    "        super(bertRegressor, self).__init__()\n",
    "        D_in, D_out = 768, 1\n",
    "        self.bert = AutoModel.from_pretrained('microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract')\n",
    "        self.regressor = nn.Sequential(\n",
    "                                        nn.Dropout(drop_rate),\n",
    "                                        nn.Linear(D_in, D_out))\n",
    "\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "\n",
    "        outputs = self.bert(input_ids, attention_masks)\n",
    "        class_label_output = outputs[1]\n",
    "        outputs = self.regressor(class_label_output)\n",
    "        return outputs\n",
    "\n",
    "def train(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value=2):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        print(\"-----\")\n",
    "        best_loss = 1e10\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "            batch_inputs, batch_masks, batch_labels = tuple(b.to(device) for b in batch)\n",
    "            model.zero_grad()\n",
    "            outputs = model(batch_inputs, batch_masks)\n",
    "            loss = loss_function(outputs.squeeze(), batch_labels.squeeze())\n",
    "            loss.backward()\n",
    "            clip_grad_norm(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "# ref: https://discuss.pytorch.org/t/rmse-loss-function/16540/3\n",
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "loss_function = RMSELoss\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    output = []\n",
    "    for batch in dataloader:\n",
    "        batch_inputs, batch_masks, _ = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output += model(batch_inputs, batch_masks).view(1,-1).tolist()[0]\n",
    "    return output\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_corpus = tokenizer(text_corpus, padding=True, truncation=True, return_tensors='pt', max_length=400)\n",
    "input_ids, attention_mask = encoded_corpus['input_ids'], encoded_corpus['attention_mask']\n",
    "\n",
    "# Define labels\n",
    "labels_difficulty = df['Difficulty'].to_numpy()\n",
    "labels_response_time = df['Response_Time'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qbu22QSMqvRs",
   "metadata": {
    "id": "qbu22QSMqvRs"
   },
   "source": [
    "### **Task 1: Predict Difficulty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "UrKJ7VzWqswG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UrKJ7VzWqswG",
    "outputId": "51252ac8-ea1c-4c8b-a63e-dbef95781dd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishikesh\\AppData\\Local\\Temp\\ipykernel_3344\\1685244855.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(inputs)\n",
      "C:\\Users\\rishikesh\\AppData\\Local\\Temp\\ipykernel_3344\\1685244855.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_tensor = torch.tensor(masks)\n",
      "D:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 4.00 GiB total capacity; 3.34 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader) \u001b[38;5;241m*\u001b[39m epochs\n\u001b[0;32m     17\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(optimizer, num_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_training_steps\u001b[38;5;241m=\u001b[39mtotal_steps)\n\u001b[1;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict(model, test_dataloader, device)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# compute rmse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value)\u001b[0m\n\u001b[0;32m     36\u001b[0m batch_inputs, batch_masks, batch_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(b\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch)\n\u001b[0;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 38\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs\u001b[38;5;241m.\u001b[39msqueeze(), batch_labels\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m     40\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mbertRegressor.forward\u001b[1;34m(self, input_ids, attention_masks)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_masks):\n\u001b[1;32m---> 22\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     class_label_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregressor(class_label_output)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1015\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[1;32m-> 1022\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1035\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    605\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 612\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llmenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:349\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    346\u001b[0m         relative_position_scores_key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhrd,lrd->bhlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[0;32m    347\u001b[0m         attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m relative_position_scores_query \u001b[38;5;241m+\u001b[39m relative_position_scores_key\n\u001b[1;32m--> 349\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mattention_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_head_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;66;03m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 4.00 GiB total capacity; 3.34 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "seed = 42\n",
    "\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_ids, labels_difficulty, test_size=test_size, random_state=seed)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_mask, labels_difficulty, test_size=test_size, random_state=seed)\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = create_dataloaders(train_inputs, train_masks, train_labels, batch_size)\n",
    "test_dataloader = create_dataloaders(test_inputs, test_masks, test_labels, batch_size)\n",
    "\n",
    "model = bertRegressor(drop_rate=0.2)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "model = train(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value=2)\n",
    "\n",
    "y_pred = predict(model, test_dataloader, device)\n",
    "\n",
    "# compute rmse\n",
    "mean_squared_error( test_labels, y_pred, squared=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apwdvUCrr6NC",
   "metadata": {
    "id": "apwdvUCrr6NC"
   },
   "source": [
    "### **Task 2: Predict Response Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a7a21-5c6d-45a6-bd0e-db6a9b8080b3",
   "metadata": {
    "id": "1e3a7a21-5c6d-45a6-bd0e-db6a9b8080b3"
   },
   "outputs": [],
   "source": [
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_ids, labels_response_time, test_size=test_size, random_state=seed)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_mask, labels_response_time, test_size=test_size, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_labels.reshape(-1, 1))\n",
    "train_labels = scaler.transform(train_labels.reshape(-1, 1))\n",
    "test_labels = scaler.transform(test_labels.reshape(-1, 1))\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = create_dataloaders(train_inputs, train_masks, train_labels, batch_size)\n",
    "test_dataloader = create_dataloaders(test_inputs, test_masks, test_labels, batch_size)\n",
    "\n",
    "model = bertRegressor(drop_rate=0.2)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "model = train(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value=2)\n",
    "\n",
    "y_pred_scaled = predict(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Triiv_6QsrkF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Triiv_6QsrkF",
    "outputId": "527d6f85-1629-4e82-a4f4-9b3bdef05487"
   },
   "outputs": [],
   "source": [
    "y_pred_scaled = np.array(y_pred_scaled)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "\n",
    "# compute rmse\n",
    "mean_squared_error( test_labels, y_pred, squared=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uu-UZmyM64dZ",
   "metadata": {
    "id": "uu-UZmyM64dZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
